<div align="center">

# ğŸ¤– ChatRAG

### Chatbot Inteligente com RAG (Retrieval-Augmented Generation)

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.128.0+-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![LangChain](https://img.shields.io/badge/LangChain-1.2.3+-1C3C3C?style=for-the-badge&logo=chainlink&logoColor=white)](https://www.langchain.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Azure](https://img.shields.io/badge/Azure_AI_Search-0078D4?style=for-the-badge&logo=microsoftazure&logoColor=white)](https://azure.microsoft.com/)

</div>

______________________________________________________________________

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [CaracterÃ­sticas](#-caracter%C3%ADsticas)
- [Arquitetura](#-arquitetura)
- [DecisÃµes TÃ©cnicas](#-decis%C3%B5es-t%C3%A9cnicas)
- [Tecnologias](#-tecnologias)
- [PrÃ©-requisitos](#-pr%C3%A9-requisitos)
- [InstalaÃ§Ã£o](#-instala%C3%A7%C3%A3o)
- [ConfiguraÃ§Ã£o](#-configura%C3%A7%C3%A3o)
- [Uso](#-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [API Endpoints](#-api-endpoints)
- [Desenvolvimento](#-desenvolvimento)
- [Docker](#-docker)
- [Contribuindo](#-contribuindo)
- [LicenÃ§a](#-licen%C3%A7a)

______________________________________________________________________

## ğŸ¯ Sobre o Projeto

**ChatRAG** Ã© uma aplicaÃ§Ã£o de chatbot inteligente que combina o poder do **Retrieval-Augmented Generation (RAG)** com modelos de linguagem avanÃ§ados. O sistema utiliza Azure AI Search para recuperaÃ§Ã£o de informaÃ§Ãµes e OpenAI para geraÃ§Ã£o de respostas contextualizadas e precisas.

### Por que ChatRAG?

- ğŸ¯ **Respostas Contextualizadas**: Combina conhecimento recuperado com IA generativa
- ğŸ” **Busca SemÃ¢ntica**: Utiliza embeddings para encontrar informaÃ§Ãµes relevantes
- ğŸ”„ **ConversaÃ§Ãµes com Estado**: MantÃ©m o contexto atravÃ©s de mÃºltiplas interaÃ§Ãµes
- âš¡ **Performance**: API rÃ¡pida e eficiente construÃ­da com FastAPI
- ğŸ³ **FÃ¡cil Deploy**: Totalmente containerizado com Docker

______________________________________________________________________

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **Chatbot Inteligente** com capacidade de manter contexto conversacional
- ğŸ” **RAG (Retrieval-Augmented Generation)** para respostas baseadas em documentos
- ğŸ§  **LangGraph** para orquestraÃ§Ã£o de fluxos de conversaÃ§Ã£o complexos
- ğŸ“Š **Azure AI Search** para indexaÃ§Ã£o e busca vetorial de alta performance
- ğŸš€ **API REST** completa com documentaÃ§Ã£o automÃ¡tica (Swagger/ReDoc)
- ğŸ” **ConfiguraÃ§Ã£o Segura** via variÃ¡veis de ambiente
- ğŸ³ **Docker Support** com Docker Compose para deploy simplificado
- âœ… **Health Checks** para monitoramento da aplicaÃ§Ã£o
- ğŸ”„ **CORS Configurado** para integraÃ§Ã£o com frontends
- ğŸ’¬ **Sistema de ClarificaÃ§Ã£o Inteligente** - O agente pode fazer perguntas de volta ao usuÃ¡rio quando precisa de mais contexto

> **ğŸ“ Nota sobre ClarificaÃ§Ãµes**: Uma "clarificaÃ§Ã£o" ocorre quando a IA, ao analisar a pergunta do usuÃ¡rio e o contexto recuperado, identifica que precisa de informaÃ§Ãµes adicionais para fornecer uma resposta precisa. Nesses casos, o agente responde com uma pergunta direcionada ao usuÃ¡rio. O sistema rastreia o nÃºmero de clarificaÃ§Ãµes para evitar loops infinitos, limitando-as a um mÃ¡ximo configurÃ¡vel (padrÃ£o: 2) antes de transferir para atendimento humano se necessÃ¡rio.

______________________________________________________________________

## ğŸ—ï¸ Arquitetura

O projeto segue princÃ­pios de **Clean Architecture** e **Domain-Driven Design (DDD)**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Layer     â”‚  â† FastAPI Routes
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Application    â”‚  â† Business Logic & LangGraph
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Domain       â”‚  â† Core Domain Models
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Infrastructure  â”‚  â† External Services (OpenAI, Azure)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de ConversaÃ§Ã£o

```mermaid
graph LR
    A[UsuÃ¡rio] --> B[API]
    B --> C[ConversationGraph]
    C --> D[Azure AI Search]
    C --> E[OpenAI LLM]
    D --> C
    E --> C
    C --> B
    B --> A
```

______________________________________________________________________

## ğŸ“ DecisÃµes TÃ©cnicas

### Por que LangChain e LangGraph?

#### **LangChain: O Framework Ideal para LLM Applications**

O **LangChain** foi escolhido como base deste projeto pelos seguintes motivos:

ğŸ”— **AbstraÃ§Ã£o Poderosa**

- Fornece componentes modulares e reutilizÃ¡veis para trabalhar com LLMs
- Facilita a integraÃ§Ã£o com mÃºltiplos provedores (OpenAI, Azure, Anthropic, etc.)
- Reduz significativamente o boilerplate code

ğŸ”„ **RAG Simplificado**

- ImplementaÃ§Ã£o nativa de Retrieval-Augmented Generation
- Suporte integrado para vector stores (Azure AI Search, Pinecone, Weaviate)
- Gerenciamento automÃ¡tico de embeddings e similarity search

ğŸ“ **Prompt Engineering**

- Templates de prompts estruturados e parametrizÃ¡veis
- Chain of Thought e outras tÃ©cnicas avanÃ§adas jÃ¡ implementadas
- Facilita testes e versionamento de prompts

ğŸ§© **Ecosystem Rico**

- Mais de 700+ integraÃ§Ãµes prontas
- Comunidade ativa e documentaÃ§Ã£o extensa
- PadrÃµes estabelecidos e best practices

#### **LangGraph: State Machine para ConversaÃ§Ãµes Complexas**

O **LangGraph** complementa o LangChain trazendo:

ğŸ”€ **Fluxos Condicionais**

- Permite criar workflows complexos com branches e loops
- Controle fino sobre o fluxo de conversaÃ§Ã£o
- Suporte a estados e transiÃ§Ãµes explÃ­citas

ğŸ’¾ **Gerenciamento de Estado**

- Checkpointing automÃ¡tico para persistÃªncia de conversas
- Memory saver integrado para contexto de longo prazo
- Rollback e replay de conversaÃ§Ãµes

ğŸ¯ **Arquitetura de Agentes**

- Suporte nativo para multi-agentes
- OrquestraÃ§Ã£o de diferentes LLMs e ferramentas
- Perfeito para implementar padrÃµes como ReAct e Plan-and-Execute

### Outras DecisÃµes Arquiteturais

#### **Clean Architecture + DDD**

```
âœ… SeparaÃ§Ã£o clara de responsabilidades
âœ… DomÃ­nio isolado de detalhes de infraestrutura
âœ… Facilita testes e manutenÃ§Ã£o
âœ… Permite troca de dependÃªncias sem impacto no core
```

#### **FastAPI como Framework Web**

- Performance comparÃ¡vel a Node.js e Go
- ValidaÃ§Ã£o automÃ¡tica com Pydantic
- DocumentaÃ§Ã£o OpenAPI gerada automaticamente
- Type hints nativos para melhor DX

#### **Azure AI Search para Vector Store**

- Busca hÃ­brida (vetorial + keyword)
- Escalabilidade enterprise-grade
- IntegraÃ§Ã£o nativa com Azure ecosystem
- Filtros e facetas avanÃ§adas

#### **UV para Gerenciamento de Pacotes**

- 10-100x mais rÃ¡pido que pip
- Lock file determinÃ­stico
- ResoluÃ§Ã£o de dependÃªncias otimizada
- CompatÃ­vel com pip e pyproject.toml

#### **Docker Multi-Stage Build**

- Imagens otimizadas e seguras
- SeparaÃ§Ã£o de build e runtime
- Health checks integrados
- FÃ¡cil deploy em qualquer ambiente

#### **Sistema de ClarificaÃ§Ã£o Inteligente**

O sistema implementa um mecanismo sofisticado de clarificaÃ§Ã£o:

**Como Funciona:**

1. O LLM analisa a pergunta do usuÃ¡rio e o contexto recuperado
1. Se a informaÃ§Ã£o for insuficiente, o agente responde com uma **contra-pergunta**
1. O sistema rastreia o contador de clarificaÃ§Ãµes para cada conversa
1. ApÃ³s o limite (padrÃ£o: 2 clarificaÃ§Ãµes), a conversa Ã© escalada para humano

**Vantagens:**

- âœ… Evita respostas genÃ©ricas ou imprecisas
- âœ… Coleta informaÃ§Ãµes especÃ­ficas antes de responder
- âœ… Melhora a satisfaÃ§Ã£o do usuÃ¡rio com respostas mais precisas
- âœ… Previne loops infinitos de perguntas
- âœ… Handover inteligente para atendimento humano quando necessÃ¡rio

**Exemplo de Fluxo:**

```
UsuÃ¡rio: "Meu sistema estÃ¡ lento"
Agente: "Para te ajudar melhor, qual parte do sistema estÃ¡ apresentando lentidÃ£o? 
         Ã‰ no login, na dashboard, ou em outra funcionalidade especÃ­fica?"
         [clarification_count: 1]

UsuÃ¡rio: "Na dashboard"
Agente: "Entendi! A lentidÃ£o na dashboard pode ser causada por... [resposta completa]"
         [clarification_count: 1, resposta final]
```

______________________________________________________________________

## ğŸ› ï¸ Tecnologias

### Core

- **[Python 3.11+](https://www.python.org/)** - Linguagem de programaÃ§Ã£o
- **[FastAPI](https://fastapi.tiangolo.com/)** - Framework web moderno e rÃ¡pido
- **[Pydantic](https://docs.pydantic.dev/)** - ValidaÃ§Ã£o de dados

### IA & Machine Learning

- **[LangChain](https://www.langchain.com/)** - Framework para aplicaÃ§Ãµes com LLMs
- **[LangGraph](https://langchain-ai.github.io/langgraph/)** - OrquestraÃ§Ã£o de agentes e workflows
- **[OpenAI](https://openai.com/)** - Modelos de linguagem (GPT-4, embeddings)

### Cloud & Infraestrutura

- **[Azure AI Search](https://azure.microsoft.com/products/ai-services/ai-search)** - Busca semÃ¢ntica e vetorial
- **[Docker](https://www.docker.com/)** - ContainerizaÃ§Ã£o
- **[uv](https://github.com/astral-sh/uv)** - Gerenciador de pacotes Python ultrarrÃ¡pido

______________________________________________________________________

## ğŸ“¦ PrÃ©-requisitos

- **Python 3.11** ou superior
- **Docker** e **Docker Compose** (opcional, para deploy containerizado)
- **Conta OpenAI** com API Key
- **Azure AI Search** com Ã­ndice configurado

______________________________________________________________________

## ğŸš€ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: InstalaÃ§Ã£o Local

1. **Clone o repositÃ³rio**

```bash
git clone https://github.com/seu-usuario/chatrag.git
cd chatrag
```

2. **Instale o uv** (se ainda nÃ£o tiver)

```bash
pip install uv
```

3. **Instale as dependÃªncias**

```bash
uv sync
```

### OpÃ§Ã£o 2: Com Docker

```bash
git clone https://github.com/seu-usuario/chatrag.git
cd chatrag
docker-compose up --build
```

______________________________________________________________________

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. Crie um arquivo `.env`

```bash
cp .env.example .env
```

### 2. Configure as variÃ¡veis de ambiente

```env
# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
OPENAI_CHAT_MODEL=gpt-4

# Azure AI Search Configuration
AZURE_SEARCH_ENDPOINT=https://your-search-service.search.windows.net
AZURE_SEARCH_KEY=your-azure-search-admin-key
AZURE_SEARCH_INDEX_NAME=your-index-name

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
MAX_CLARIFICATIONS=2
```

### 3. VariÃ¡veis de Ambiente DisponÃ­veis

| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `OPENAI_API_KEY` | Chave da API OpenAI | *ObrigatÃ³rio* |
| `OPENAI_EMBEDDING_MODEL` | Modelo de embeddings | `text-embedding-ada-002` |
| `OPENAI_CHAT_MODEL` | Modelo de chat | `gpt-4` |
| `AZURE_SEARCH_ENDPOINT` | Endpoint do Azure AI Search | *ObrigatÃ³rio* |
| `AZURE_SEARCH_KEY` | Chave de acesso do Azure Search | *ObrigatÃ³rio* |
| `AZURE_SEARCH_INDEX_NAME` | Nome do Ã­ndice | *ObrigatÃ³rio* |
| `APP_HOST` | Host da aplicaÃ§Ã£o | `0.0.0.0` |
| `APP_PORT` | Porta da aplicaÃ§Ã£o | `8000` |
| `MAX_CLARIFICATIONS` | MÃ¡ximo de clarificaÃ§Ãµes | `2` |

______________________________________________________________________

## ğŸ’» Uso

### Executar Localmente

```bash
# Ative o ambiente virtual do uv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Execute a aplicaÃ§Ã£o
uv run fastapi dev main.py
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:8000`

### Acessar a DocumentaÃ§Ã£o

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Exemplo de RequisiÃ§Ã£o

```bash
curl --location 'http://localhost:8000/conversations/completions' \
--header 'Content-Type: application/json' \
--data '{
  "helpdeskId": 1,
  "projectName": "tesla_motors",
  "messages": [
    {
      "role": "USER",
      "content": "Hi! What'\''s the autonomy of a Tesla car?"
    }
  ]
}'
```

______________________________________________________________________

## ğŸ“‚ Estrutura do Projeto

```
chatrag/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ api/              # Rotas e endpoints FastAPI
â”‚   â”œâ”€â”€ ğŸ“ application/      # LÃ³gica de negÃ³cio e LangGraph
â”‚   â”œâ”€â”€ ğŸ“ domain/           # Modelos de domÃ­nio e entidades
â”‚   â””â”€â”€ ğŸ“ infrastructure/   # ConfiguraÃ§Ãµes e serviÃ§os externos
â”œâ”€â”€ ğŸ“„ main.py               # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ ğŸ“„ pyproject.toml        # DependÃªncias e metadados
â”œâ”€â”€ ğŸ“„ Dockerfile            # Imagem Docker
â”œâ”€â”€ ğŸ“„ docker-compose.yml    # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ ğŸ“„ .env.example          # Exemplo de variÃ¡veis de ambiente
â””â”€â”€ ğŸ“„ README.md             # Este arquivo
```

______________________________________________________________________

## ğŸŒ API Endpoints

### Root

- **GET /** - InformaÃ§Ãµes da API

### Health

- **GET /health** - Status da aplicaÃ§Ã£o

### ConversaÃ§Ãµes

- **POST /conversations** - Enviar mensagem e receber resposta
  ```json
    {
      "helpdeskId": 20,
      "projectName": "tesla_motors",
      "messages": [
        {
          "role": "USER",
          "content": "Hi! What's the autonomy of a Tesla car?"
        }
      ]
    }
  ```

### DocumentaÃ§Ã£o

- **GET /docs** - Swagger UI
- **GET /redoc** - ReDoc

______________________________________________________________________

## ğŸ‘¨â€ğŸ’» Desenvolvimento

### Instalar com dependÃªncias de desenvolvimento

```bash
uv sync
```

### Executar em modo desenvolvimento

```bash
uv run fastapi dev main.py
```

### Estrutura de CÃ³digo

O projeto segue os princÃ­pios:

- âœ… **Clean Architecture**
- âœ… **SOLID Principles**
- âœ… **Type Hints** em todo o cÃ³digo
- âœ… **ValidaÃ§Ã£o com Pydantic**
- âœ… **Separation of Concerns**

______________________________________________________________________

## ğŸ³ Docker

### Build da Imagem

```bash
docker build -t chatrag:latest .
```

### Executar Container

```bash
docker run -p 8000:8000 --env-file .env chatrag:latest
```

### Docker Compose

```bash
# Iniciar serviÃ§os
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar serviÃ§os
docker-compose down
```

### Health Check

O container possui health check configurado:

```yaml
healthcheck:
  test: python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health').read()"
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 10s
```

______________________________________________________________________

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

______________________________________________________________________

<div align="center">

**Desenvolvido com â¤ï¸ usando Python, FastAPI e LangChain**

</div>
